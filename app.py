# app.py
import streamlit as st
import pandas as pd
from ast import literal_eval # –î–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ø–∏—Å–∫–æ–≤ –∏–∑ —Å—Ç—Ä–æ–∫
import os # –î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
# st.set_page_config –î–û–õ–ñ–ù–ê –±—ã—Ç—å –ø–µ—Ä–≤–æ–π –∫–æ–º–∞–Ω–¥–æ–π Streamlit
st.set_page_config(
    layout="wide", # –ò—Å–ø–æ–ª—å–∑—É–µ–º —à–∏—Ä–æ–∫—É—é —Ä–∞—Å–∫–ª–∞–¥–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    page_title="–ê–Ω–∞–ª–∏–∑ –¥–Ω–µ–≤–Ω–∏–∫–∞ –≥–∏–º–Ω–∞–∑–∏—Å—Ç–∞", # –ù–∞–∑–≤–∞–Ω–∏–µ –≤–æ –≤–∫–ª–∞–¥–∫–µ –±—Ä–∞—É–∑–µ—Ä–∞
    page_icon="üìú" # –ò–∫–æ–Ω–∫–∞ –≤–æ –≤–∫–ª–∞–¥–∫–µ –±—Ä–∞—É–∑–µ—Ä–∞
)

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—É—Ç–µ–π ---
# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞ app.py
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º pickle –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
DATA_PATH_PKL = os.path.join(BASE_DIR, 'merged_diary_events.pkl')
# –†–µ–∑–µ—Ä–≤–Ω—ã–π –ø—É—Ç—å –∫ CSV
DATA_PATH_CSV = os.path.join(BASE_DIR, 'merged_diary_events.csv')


# --- –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º ---
@st.cache_data # –ö—ç—à–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏—Ö –ø—Ä–∏ –∫–∞–∂–¥–æ–º –¥–µ–π—Å—Ç–≤–∏–∏
def load_data(pkl_path, csv_path):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ Pickle –∏–ª–∏ CSV.

    Args:
        pkl_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É .pkl.
        csv_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É .csv (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π).

    Returns:
        pandas.DataFrame: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame –∏–ª–∏ –ø—É—Å—Ç–æ–π DataFrame –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏.
    """
    df = None
    loaded_from = None

    if os.path.exists(pkl_path):
        try:
            df = pd.read_pickle(pkl_path)
            print(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ pickle: '{pkl_path}'.")
            loaded_from = 'pickle'
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ pickle —Ñ–∞–π–ª–∞ '{pkl_path}': {e}. –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV.")
            df = None # –°–±—Ä–∞—Å—ã–≤–∞–µ–º df –Ω–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–∫–∏
    else:
        st.warning(f"–§–∞–π–ª pickle '{pkl_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    if df is None: # –ï—Å–ª–∏ pickle –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        if os.path.exists(csv_path):
            st.warning(f"–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV: '{csv_path}'")
            try:
                df = pd.read_csv(csv_path)
                print("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ CSV.")
                loaded_from = 'csv'
                # –ü–æ–ø—ã—Ç–∫–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ pickle –¥–ª—è –±—É–¥—É—â–∏—Ö –∑–∞–ø—É—Å–∫–æ–≤
                try:
                    df.to_pickle(pkl_path)
                    print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ pickle —Ñ–æ—Ä–º–∞—Ç–µ: '{pkl_path}' –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –±—É–¥—É—â–∏—Ö –∑–∞–≥—Ä—É–∑–æ–∫.")
                except Exception as pkl_save_error:
                    print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ pickle: {pkl_save_error}")
            except Exception as csv_load_error:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CSV —Ñ–∞–π–ª–∞ '{csv_path}': {csv_load_error}")
                return pd.DataFrame()
        else:
             st.error(f"–†–µ–∑–µ—Ä–≤–Ω—ã–π CSV —Ñ–∞–π–ª '{csv_path}' —Ç–∞–∫–∂–µ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
             return pd.DataFrame()

    # --- –û—á–∏—Å—Ç–∫–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ) ---
    if df is not None and not df.empty:
        try:
            # 1. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç
            date_col_to_use = None
            if 'source_date' in df.columns:
                date_col_to_use = 'source_date'
            elif 'date' in df.columns:
                date_col_to_use = 'date'
                print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–ª–æ–Ω–∫–∞ 'date' –¥–Ω–µ–≤–Ω–∏–∫–∞ –∫–∞–∫ –æ—Å–Ω–æ–≤–∞ –¥–ª—è 'source_date_dt'.")

            if date_col_to_use:
                 # errors='coerce' –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞—Ç—ã –≤ NaT (Not a Time)
                 df['source_date_dt'] = pd.to_datetime(df[date_col_to_use], errors='coerce')
                 print(f"–ö–æ–ª–æ–Ω–∫–∞ 'source_date_dt' —Å–æ–∑–¥–∞–Ω–∞ –∏–∑ '{date_col_to_use}'.")
            else:
                print("–û—à–∏–±–∫–∞: –ù–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ 'source_date' –∏–ª–∏ 'date'. –°–æ–∑–¥–∞—é –ø—É—Å—Ç—É—é –∫–æ–ª–æ–Ω–∫—É 'source_date_dt'.")
                df['source_date_dt'] = pd.NaT # Not a Time –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –¥–∞—Ç

            # 2. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 'keywords' –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤ —Å–ø–∏—Å–æ–∫
            if 'keywords' in df.columns and loaded_from == 'csv': # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≥—Ä—É–∑–∏–ª–∏ –∏–∑ CSV
                 print("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 'keywords' (–∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ CSV)...")
                 def safe_literal_eval(val):
                     if isinstance(val, list): return val
                     try:
                         if pd.isna(val) or not isinstance(val, str): return []
                         if not val.strip() or val.strip() == '[]': return []
                         # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ª–∏—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏, –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Ç–∏–ø–∞ "'[...]'":
                         if val.startswith("'") and val.endswith("'"):
                             val = val[1:-1]
                         res = literal_eval(val)
                         return res if isinstance(res, list) else []
                     except (ValueError, SyntaxError, TypeError):
                         return []
                     except Exception as e:
                          print(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ keywords '{val}': {e}")
                          return []
                 df['keywords'] = df['keywords'].apply(safe_literal_eval)
            elif 'keywords' in df.columns:
                 # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –≤ keywords, –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ pickle (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
                  df['keywords'] = df['keywords'].apply(lambda x: x if isinstance(x, list) else [])
                  print("–ö–æ–ª–æ–Ω–∫–∞ 'keywords' –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞ (–∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ pickle).")


            # 3. –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ entry_id —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if 'entry_id' not in df.columns:
                print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ö–æ–ª–æ–Ω–∫–∞ 'entry_id' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –°–æ–∑–¥–∞—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω–¥–µ–∫—Å–∞.")
                df['entry_id'] = df.index

            # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ NaN –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö —Å–æ–±—ã—Ç–∏—è
            event_text_cols = ['event_name', 'description', 'date_in_text', 'location', 'historical_context', 'confidence', 'text_fragment']
            for col in event_text_cols:
                if col in df.columns:
                    df[col] = df[col].fillna('N/A') # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

            print("–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
            return df

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return pd.DataFrame()
    else:
        # –ï—Å–ª–∏ df –ø—É—Å—Ç –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
        return pd.DataFrame()


# --- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
df_merged = load_data(DATA_PATH_PKL, DATA_PATH_CSV)

# --- –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
# –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–µ–ø–µ—Ä—å –∏–¥–µ—Ç –ü–û–°–õ–ï set_page_config
st.title("–ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π –≤ –¥–Ω–µ–≤–Ω–∏–∫–µ –≥–∏–º–Ω–∞–∑–∏—Å—Ç–∞ XIX –≤–µ–∫–∞")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
if df_merged.empty:
    st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ 'merged_diary_events.pkl' –∏–ª–∏ 'merged_diary_events.csv' –∏ –∏—Ö —Ñ–æ—Ä–º–∞—Ç.")
    # st.stop() –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –í–°–ï–• –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –∫–æ–º–∞–Ω–¥ Streamlit –≤ —Å–∫—Ä–∏–ø—Ç–µ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏.
    # –≠—Ç–æ –ø–æ–ª–µ–∑–Ω–æ, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –æ—à–∏–±–∫–∏, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.
    st.stop()

# --- –§–∏–ª—å—Ç—Ä—ã –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ ---
st.sidebar.header("–§–∏–ª—å—Ç—Ä—ã –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")

# –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π df_merged
df_filtered = df_merged.copy()

# --- –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ ---
date_col_present = 'source_date_dt' in df_filtered.columns and not df_filtered['source_date_dt'].isna().all()
if date_col_present:
    min_date_val = df_filtered['source_date_dt'].min()
    max_date_val = df_filtered['source_date_dt'].max()
    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ min/max –Ω–µ NaT
    if pd.notna(min_date_val) and pd.notna(max_date_val):
        min_date = min_date_val.date()
        max_date = max_date_val.date()
        if min_date <= max_date:
            try:
                date_range = st.sidebar.date_input(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –∑–∞–ø–∏—Å–µ–π",
                    value=(min_date, max_date), # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    min_value=min_date,
                    max_value=max_date,
                    key='date_filter' # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –≤–∏–¥–∂–µ—Ç–∞
                )
                if len(date_range) == 2:
                    start_date, end_date = date_range
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –¥–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –¥–∏–∞–ø–∞–∑–æ–Ω
                    df_filtered = df_filtered[
                        df_filtered['source_date_dt'].notna() &
                        (df_filtered['source_date_dt'].dt.date >= start_date) &
                        (df_filtered['source_date_dt'].dt.date <= end_date)
                    ]
            except Exception as e:
                st.sidebar.error(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–µ: {e}")
        else:
            st.sidebar.warning("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç (min > max).")
    else:
        st.sidebar.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (min/max - NaT).")
else:
    st.sidebar.info("–ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–∞–º–∏ ('source_date') –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.")


# --- –§–∏–ª—å—Ç—Ä –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º ---
keywords_col_present = 'keywords' in df_filtered.columns
if keywords_col_present:
    all_keywords_flat = [k for sublist in df_filtered['keywords'].dropna() if isinstance(sublist, list) for k in sublist if k and isinstance(k, str)]
    unique_keywords = sorted(list(set(all_keywords_flat)))

    if unique_keywords:
        selected_keywords = st.sidebar.multiselect(
            "–§–∏–ª—å—Ç—Ä –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (–ò)",
            options=unique_keywords,
            key='keyword_filter'
        )
        if selected_keywords:
            def check_keywords(keyword_list):
                if not isinstance(keyword_list, list): return False
                return all(sel_k in keyword_list for sel_k in selected_keywords)
            df_filtered = df_filtered[df_filtered['keywords'].apply(check_keywords)]
    else:
        st.sidebar.info("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤ —Ç–µ–∫—É—â–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö.")
else:
    st.sidebar.info("–ö–æ–ª–æ–Ω–∫–∞ 'keywords' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")


# --- –§–∏–ª—å—Ç—Ä –ø–æ —É—Ä–æ–≤–Ω—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ ---
confidence_col_present = 'confidence' in df_filtered.columns
if confidence_col_present:
    confidence_levels = sorted([lvl for lvl in df_filtered['confidence'].dropna().unique() if lvl != 'N/A'])
    if confidence_levels:
        selected_confidence = st.sidebar.multiselect(
            "–§–∏–ª—å—Ç—Ä –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏",
            options=confidence_levels,
            key='confidence_filter'
        )
        if selected_confidence:
            df_filtered = df_filtered[df_filtered['confidence'].isin(selected_confidence)]
    else:
        st.sidebar.info("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
else:
    st.sidebar.info("–ö–æ–ª–æ–Ω–∫–∞ 'confidence' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")


# --- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---
st.header("–û–±–∑–æ—Ä –∑–∞–ø–∏—Å–µ–π –∏ —Å–æ–±—ã—Ç–∏–π (–æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ)")
display_columns = ['entry_id', 'date', 'event_name', 'description', 'location', 'confidence', 'keywords']
actual_display_columns = [col for col in display_columns if col in df_filtered.columns]

if not df_filtered.empty:
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É—Ä–µ–∑–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –æ–±–∑–æ—Ä–∞
    st.dataframe(df_filtered[actual_display_columns], height=300) # –û–≥—Ä–∞–Ω–∏—á–∏–º –≤—ã—Å–æ—Ç—É
    st.write(f"–û—Ç–æ–±—Ä–∞–Ω–æ —Å—Ç—Ä–æ–∫: {len(df_filtered)}")
else:
    st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º.")


# --- –î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–ø–∏—Å–∏ ---
st.header("–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–ø–∏—Å–∏")

entry_id_present = 'entry_id' in df_filtered.columns
if not df_filtered.empty and entry_id_present:
    available_entry_ids = sorted(df_filtered['entry_id'].unique())
    if available_entry_ids:
        selected_entry_id = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ ID –∑–∞–ø–∏—Å–∏ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞:",
            options=available_entry_ids,
            key='entry_selector',
            index=None, # –ù–µ –≤—ã–±–∏—Ä–∞—Ç—å –Ω–∏—á–µ–≥–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            placeholder="–í—ã–±–µ—Ä–∏—Ç–µ ID..." # –ü–æ–¥—Å–∫–∞–∑–∫–∞
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ ID –±—ã–ª –≤—ã–±—Ä–∞–Ω
        if selected_entry_id is not None:
            entry_data_full = df_merged[df_merged['entry_id'] == selected_entry_id]
            if not entry_data_full.empty:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º .iloc[0] –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–≤–æ–π (–∏, –≤–æ–∑–º–æ–∂–Ω–æ, –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π) —Å—Ç—Ä–æ–∫–∏ —Å —ç—Ç–∏–º ID
                diary_date = entry_data_full['date'].iloc[0] if 'date' in entry_data_full.columns else 'N/A'
                diary_text = entry_data_full['text'].iloc[0] if 'text' in entry_data_full.columns else '–¢–µ–∫—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'

                st.subheader(f"–ó–∞–ø–∏—Å—å –æ—Ç {diary_date} (ID: {selected_entry_id})")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º markdown –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                st.markdown("#### –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–ø–∏—Å–∏:")
                st.markdown(f"<div style='height: 300px; overflow-y: auto; border: 1px solid #ccc; padding: 10px;'>{diary_text}</div>", unsafe_allow_html=True)
                # st.text_area("–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–ø–∏—Å–∏:", diary_text, height=300, key=f'text_area_{selected_entry_id}') # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞

                st.subheader("–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è:")
                events_in_entry = entry_data_full[
                    entry_data_full['event_name'].notna() & (entry_data_full['event_name'] != 'N/A')
                ].drop_duplicates(subset=['event_name', 'text_fragment'])

                if not events_in_entry.empty:
                    for i, (_, event_row) in enumerate(events_in_entry.iterrows()):
                        st.markdown("---")
                        event_name = event_row.get('event_name', 'N/A')
                        st.markdown(f"**–°–æ–±—ã—Ç–∏–µ {i+1}: {event_name}**")
                        with st.expander(f"–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Å–æ–±—ã—Ç–∏–∏: {event_name}"):
                            st.markdown(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {event_row.get('description', 'N/A')}")
                            st.markdown(f"**–î–∞—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ:** {event_row.get('date_in_text', 'N/A')}")
                            st.markdown(f"**–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ:** {event_row.get('location', 'N/A')}")
                            st.markdown(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {event_row.get('confidence', 'N/A')}")

                            keywords = event_row.get('keywords', [])
                            if isinstance(keywords, list) and keywords:
                                valid_keywords = [str(k).strip() for k in keywords if k and isinstance(k, str) and str(k).strip()]
                                if valid_keywords:
                                     st.markdown(f"**–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:** {' | '.join([f'`{k}`' for k in valid_keywords])}")
                            elif keywords != 'N/A':
                                st.markdown(f"**–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:** {keywords}")

                            st.markdown(f"**–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:**")
                            st.caption(f"{event_row.get('historical_context', 'N/A')}")

                            st.markdown(f"**–¶–∏—Ç–∏—Ä—É–µ–º—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞:**")
                            st.info(f"{event_row.get('text_fragment', 'N/A')}")
                else:
                    st.info("–î–ª—è —ç—Ç–æ–π –∑–∞–ø–∏—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π.")
            else:
                 st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ —Å ID {selected_entry_id} –≤ –∏—Å—Ö–æ–¥–Ω–æ–º DataFrame.")
    else:
        st.info("–ù–µ—Ç –∑–∞–ø–∏—Å–µ–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ç–µ–∫—É—â–∏–º —Ñ–∏–ª—å—Ç—Ä–∞–º, –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞.")
else:
    st.info("–ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–µ—Ç–∞–ª–µ–π –∑–∞–ø–∏—Å–µ–π.")
    if not entry_id_present:
         st.warning("–ö–æ–ª–æ–Ω–∫–∞ 'entry_id' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö.")


# --- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ —Å–æ–±—ã—Ç–∏–π ---
st.header("–í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ —Å–æ–±—ã—Ç–∏–π")

timeline_possible = ('source_date_dt' in df_filtered.columns and
                     'event_name' in df_filtered.columns and
                     not df_filtered.empty)

if timeline_possible:
    timeline_data = df_filtered[
        (df_filtered['event_name'] != 'N/A') &
        df_filtered['source_date_dt'].notna()
    ].copy()

    if not timeline_data.empty:
        timeline_data.set_index('source_date_dt', inplace=True)
        aggregation_period = st.selectbox(
            "–ü–µ—Ä–∏–æ–¥ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã:",
            options=['D', 'W', 'M', 'Q', 'Y'],
            index=2,
            format_func=lambda x: {'D':'–î–µ–Ω—å', 'W':'–ù–µ–¥–µ–ª—è', 'M':'–ú–µ—Å—è—Ü', 'Q':'–ö–≤–∞—Ä—Ç–∞–ª', 'Y':'–ì–æ–¥'}.get(x, x),
            key='timeline_agg'
        )
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º .size() –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Å—Ç—Ä–æ–∫ (—Å–æ–±—ã—Ç–∏–π) –≤ –∫–∞–∂–¥–æ–º –ø–µ—Ä–∏–æ–¥–µ
            timeline_counts = timeline_data.resample(aggregation_period).size()
            timeline_counts = timeline_counts.rename("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π")

            if not timeline_counts.empty:
                st.line_chart(timeline_counts)
                st.caption(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º '{aggregation_period}' (–Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞—Ç—ã –∑–∞–ø–∏—Å–∏ –≤ –¥–Ω–µ–≤–Ω–∏–∫–µ).")
            else:
                st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –ø–µ—Ä–∏–æ–¥—É.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã: {e}")
    else:
        st.info("–ù–µ—Ç —Å–æ–±—ã—Ç–∏–π —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏ –≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã.")
else:
    st.info("–ù–µ–æ–±—Ö–æ–¥–∏–º—ã –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏ ('source_date') –∏ —Å–æ–±—ã—Ç–∏—è–º–∏ ('event_name') –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã.")

# --- –ö–æ–Ω–µ—Ü –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---