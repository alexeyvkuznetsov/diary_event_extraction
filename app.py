# app.py
import streamlit as st
import pandas as pd
from ast import literal_eval # –î–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ø–∏—Å–∫–æ–≤ –∏–∑ —Å—Ç—Ä–æ–∫
import os # –î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
import json # –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ö–∞—Ä—Ç—ã –ó–Ω–∞–Ω–∏–π –∏–∑ —Å—Ç—Ä–æ–∫–∏

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
# st.set_page_config –î–û–õ–ñ–ù–ê –±—ã—Ç—å –ø–µ—Ä–≤–æ–π –∫–æ–º–∞–Ω–¥–æ–π Streamlit
st.set_page_config(
    layout="wide", # –ò—Å–ø–æ–ª—å–∑—É–µ–º —à–∏—Ä–æ–∫—É—é —Ä–∞—Å–∫–ª–∞–¥–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    page_title="–ê–Ω–∞–ª–∏–∑ –¥–Ω–µ–≤–Ω–∏–∫–∞ –≥–∏–º–Ω–∞–∑–∏—Å—Ç–∞ v3", # –ù–∞–∑–≤–∞–Ω–∏–µ –≤–æ –≤–∫–ª–∞–¥–∫–µ –±—Ä–∞—É–∑–µ—Ä–∞
    page_icon="üìú" # –ò–∫–æ–Ω–∫–∞ –≤–æ –≤–∫–ª–∞–¥–∫–µ –±—Ä–∞—É–∑–µ—Ä–∞
)

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—É—Ç–µ–π ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_PATH_PKL = os.path.join(BASE_DIR, 'merged_diary_events_v3.pkl') # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø—É—Ç—å
DATA_PATH_CSV = os.path.join(BASE_DIR, 'merged_diary_events_v3.csv') # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø—É—Ç—å

# --- –ö–∞—Ä—Ç–∞ –ó–Ω–∞–Ω–∏–π (–≤—Å—Ç—Ä–æ–µ–Ω–∞ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞, –ª—É—á—à–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏–∑ —Ñ–∞–π–ª–∞) ---
KNOWLEDGE_MAP_JSON = """
[
  {
    "category_id": "REV1848", "category_name": "–†–µ–≤–æ–ª—é—Ü–∏–∏ –∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã 1848-1849 –≥–≥.",
    "subcategories": [
      {"subcategory_id": "REV1848_HUN", "subcategory_name": "–í–µ–Ω–≥–µ—Ä—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–∏–µ 1848-1849 –≥–≥.", "events": [
          {"event_id": "REV1848_HUN_INT", "event_name": "–†–æ—Å—Å–∏–π—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–≤–µ–Ω—Ü–∏—è –≤ –í–µ–Ω–≥—Ä–∏–∏ (1849)"},
          {"event_id": "REV1848_HUN_MIL", "event_name": "–í–æ–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (–í–µ–Ω–≥—Ä–∏—è, –æ–±—â–µ–µ)"},
          {"event_id": "REV1848_HUN_CAP", "event_name": "–ö–∞–ø–∏—Ç—É–ª—è—Ü–∏—è –≤–µ–Ω–≥–µ—Ä—Å–∫–æ–π –∞—Ä–º–∏–∏ (–í–∏–ª–∞–≥–æ—à)"},
          {"event_id": "REV1848_HUN_FIG", "event_name": "–£–ø–æ–º–∏–Ω–∞–Ω–∏—è –ª–∏—á–Ω–æ—Å—Ç–µ–π (–ë–µ–º, –ü–∞—Å–∫–µ–≤–∏—á)"} ]},
      {"subcategory_id": "REV1848_ITA", "subcategory_name": "–†–µ–≤–æ–ª—é—Ü–∏–∏ –≤ –ò—Ç–∞–ª–∏–∏", "events": [
          {"event_id": "REV1848_ITA_ROM", "event_name": "–†–∏–º—Å–∫–∞—è —Ä–µ—Å–ø—É–±–ª–∏–∫–∞ (1849)"},
          {"event_id": "REV1848_ITA_AUS", "event_name": "–ê–≤—Å—Ç—Ä–æ-—Å–∞—Ä–¥–∏–Ω—Å–∫–∞—è –≤–æ–π–Ω–∞ (1848-1849)"} ]},
      {"subcategory_id": "REV1848_GER", "subcategory_name": "–†–µ–≤–æ–ª—é—Ü–∏–∏ –≤ –ì–µ—Ä–º–∞–Ω–∏–∏/–ü—Ä—É—Å—Å–∏–∏ (–æ–±—â–µ–µ)"},
      {"subcategory_id": "REV1848_FRA", "subcategory_name": "–†–µ–≤–æ–ª—é—Ü–∏–∏ –≤–æ –§—Ä–∞–Ω—Ü–∏–∏ (–æ–±—â–µ–µ)"},
      {"subcategory_id": "REV1848_EUR", "subcategory_name": "–û–±—â–µ–µ–≤—Ä–æ–ø–µ–π—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç/–ë–µ—Å–ø–æ—Ä—è–¥–∫–∏ –Ω–∞ –ó–∞–ø–∞–¥–µ"}
    ]
  },
  {
    "category_id": "EPIDEMIC", "category_name": "–≠–ø–∏–¥–µ–º–∏–∏ –∏ –∑–¥–æ—Ä–æ–≤—å–µ",
    "subcategories": [
       {"subcategory_id": "EPIDEMIC_CHOLERA", "subcategory_name": "–≠–ø–∏–¥–µ–º–∏—è —Ö–æ–ª–µ—Ä—ã (1848-1849)", "events": [
            {"event_id": "EPIDEMIC_CHOLERA_SPB", "event_name": "–•–æ–ª–µ—Ä–∞ –≤ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ"},
            {"event_id": "EPIDEMIC_CHOLERA_NOV", "event_name": "–•–æ–ª–µ—Ä–∞ –≤ –ù–æ–≤–≥–æ—Ä–æ–¥—Å–∫–æ–π –≥—É–±–µ—Ä–Ω–∏–∏"},
            {"event_id": "EPIDEMIC_CHOLERA_VOL", "event_name": "–•–æ–ª–µ—Ä–∞ –≤ –í–æ–ª–æ–≥–¥–µ (—Å–ª—É—Ö–∏/—É–ø–æ–º–∏–Ω–∞–Ω–∏—è)"},
            {"event_id": "EPIDEMIC_CHOLERA_DTH", "event_name": "–°–º–µ—Ä—Ç—å –æ—Ç —Ö–æ–ª–µ—Ä—ã"},
            {"event_id": "EPIDEMIC_CHOLERA_FEAR", "event_name": "–û–ø–∞—Å–µ–Ω–∏—è/–°—Ç—Ä–∞—Ö –ø–µ—Ä–µ–¥ —Ö–æ–ª–µ—Ä–æ–π"} ]},
       {"subcategory_id": "EPIDEMIC_OTH", "subcategory_name": "–î—Ä—É–≥–∏–µ –±–æ–ª–µ–∑–Ω–∏"}
    ]
  },
  {
    "category_id": "RU_POLITICS", "category_name": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–æ–ª–∏—Ç–∏–∫–∞ –∏ –æ–±—â–µ—Å—Ç–≤–æ –†–æ—Å—Å–∏–π—Å–∫–æ–π –ò–º–ø–µ—Ä–∏–∏",
    "subcategories": [
      {"subcategory_id": "RU_POLITICS_REPRESS", "subcategory_name": "–†–µ–ø—Ä–µ—Å—Å–∏–∏ –∏ —Ü–µ–Ω–∑—É—Ä–∞ (–ù–∏–∫–æ–ª–∞–π I)", "events": [
            {"event_id": "RU_POLITICS_REPRESS_PETR", "event_name": "–î–µ–ª–æ –ø–µ—Ç—Ä–∞—à–µ–≤—Ü–µ–≤"},
            {"event_id": "RU_POLITICS_REPRESS_CENS", "event_name": "–£—Å–∏–ª–µ–Ω–∏–µ —Ü–µ–Ω–∑—É—Ä—ã –ø–µ—á–∞—Ç–∏"},
            {"event_id": "RU_POLITICS_REPRESS_SHAVE", "event_name": "–£–∫–∞–∑ –æ–± –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–º –±—Ä–∏—Ç—å–µ"},
            {"event_id": "RU_POLITICS_REPRESS_POLICE", "event_name": "–£–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ç–∞–π–Ω–æ–π –ø–æ–ª–∏—Ü–∏–∏"} ]},
      {"subcategory_id": "RU_POLITICS_IMPERIAL", "subcategory_name": "–ò–º–ø–µ—Ä–∞—Ç–æ—Ä—Å–∫–∞—è —Å–µ–º—å—è –∏ –¥–≤–æ—Ä", "events": [
           {"event_id": "RU_POLITICS_IMPERIAL_CORON", "event_name": "–ì–æ–¥–æ–≤—â–∏–Ω–∞ –∫–æ—Ä–æ–Ω–∞—Ü–∏–∏ –ù–∏–∫–æ–ª–∞—è I"},
           {"event_id": "RU_POLITICS_IMPERIAL_DEATH", "event_name": "–°–º–µ—Ä—Ç—å –í–µ–ª–∏–∫–æ–≥–æ –ö–Ω—è–∑—è –ú–∏—Ö–∞–∏–ª–∞ –ü–∞–≤–ª–æ–≤–∏—á–∞"} ]},
       {"subcategory_id": "RU_POLITICS_SOCIAL", "subcategory_name": "–°–æ—Ü–∏–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã/–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è", "events": [
           {"event_id": "RU_POLITICS_SOCIAL_REVMOOD", "event_name": "–†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –º–æ–ª–æ–¥–µ–∂–∏"} ]}
    ]
  },
   {
    "category_id": "RU_FOREIGN", "category_name": "–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è (–≤–Ω–µ 1848)",
    "subcategories": [
      {"subcategory_id": "RU_FOREIGN_TURK", "subcategory_name": "–†–æ—Å—Å–∏–π—Å–∫–æ-—Ç—É—Ä–µ—Ü–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è", "events": [
           {"event_id": "RU_FOREIGN_TURK_WAR", "event_name": "–°–ª—É—Ö–∏ –æ –≤–æ–∑–º–æ–∂–Ω–æ–π –†—É—Å—Å–∫–æ-—Ç—É—Ä–µ—Ü–∫–æ–π –≤–æ–π–Ω–µ (1849)"},
           {"event_id": "RU_FOREIGN_TURK_DIPLO", "event_name": "–î–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–∏—Å—Å–∏–∏ (–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω–æ–ø–æ–ª—å)"} ]}
      ]
   },
  {"category_id": "OTHER", "category_name": "–î—Ä—É–≥–æ–µ / –ù–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ"}
]
"""
# –ó–∞–≥—Ä—É–∑–∫–∞ –ö–∞—Ä—Ç—ã –ó–Ω–∞–Ω–∏–π
try:
    KNOWLEDGE_MAP = json.loads(KNOWLEDGE_MAP_JSON)
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ –∏–º–µ–Ω–∞–º –ø–æ ID
    KM_CATEGORY_NAMES = {cat['category_id']: cat['category_name'] for cat in KNOWLEDGE_MAP}
    KM_SUBCATEGORY_NAMES = {
        subcat['subcategory_id']: subcat['subcategory_name']
        for cat in KNOWLEDGE_MAP if 'subcategories' in cat
        for subcat in cat['subcategories']
    }
    KM_EVENT_NAMES = {
        event['event_id']: event['event_name']
        for cat in KNOWLEDGE_MAP if 'subcategories' in cat
        for subcat in cat['subcategories'] if 'events' in subcat
        for event in subcat['events']
    }
    print("–ö–∞—Ä—Ç–∞ –ó–Ω–∞–Ω–∏–π —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞.")
except json.JSONDecodeError as e:
    st.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ö–∞—Ä—Ç—É –ó–Ω–∞–Ω–∏–π: {e}")
    KNOWLEDGE_MAP = []
    KM_CATEGORY_NAMES = {}
    KM_SUBCATEGORY_NAMES = {}
    KM_EVENT_NAMES = {}
    # –ú–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –µ—Å–ª–∏ –∫–∞—Ä—Ç–∞ –∑–Ω–∞–Ω–∏–π –∫—Ä–∏—Ç–∏—á–Ω–∞
    # st.stop()

# --- –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º ---
@st.cache_data
def load_data(pkl_path, csv_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Pickle –∏–ª–∏ CSV."""
    df = None
    loaded_from = None
    if os.path.exists(pkl_path):
        try:
            df = pd.read_pickle(pkl_path)
            print(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ pickle: '{pkl_path}'.")
            loaded_from = 'pickle'
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ pickle —Ñ–∞–π–ª–∞ '{pkl_path}': {e}. –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV.")
            df = None
    else:
        st.warning(f"–§–∞–π–ª pickle '{pkl_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    if df is None:
        if os.path.exists(csv_path):
            st.warning(f"–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV: '{csv_path}'")
            try:
                df = pd.read_csv(csv_path)
                print("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ CSV.")
                loaded_from = 'csv'
                try:
                    df.to_pickle(pkl_path)
                    print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ pickle —Ñ–æ—Ä–º–∞—Ç–µ: '{pkl_path}'.")
                except Exception as pkl_save_error:
                    print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ pickle: {pkl_save_error}")
            except Exception as csv_load_error:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CSV —Ñ–∞–π–ª–∞ '{csv_path}': {csv_load_error}")
                return pd.DataFrame()
        else:
             st.error(f"–†–µ–∑–µ—Ä–≤–Ω—ã–π CSV —Ñ–∞–π–ª '{csv_path}' —Ç–∞–∫–∂–µ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
             return pd.DataFrame()

    if df is not None and not df.empty:
        try:
            # 1. –î–∞—Ç—ã
            date_col_to_use = None
            if 'source_date' in df.columns: date_col_to_use = 'source_date'
            elif 'date' in df.columns: date_col_to_use = 'date'; print("Info: Using 'date' for 'source_date_dt'.")
            if date_col_to_use: df['source_date_dt'] = pd.to_datetime(df[date_col_to_use], errors='coerce')
            else: df['source_date_dt'] = pd.NaT; print("Error: No date column found.")

            # 2. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–ø–∞—Ä—Å–∏–º, –µ—Å–ª–∏ –≥—Ä—É–∑–∏–ª–∏ –∏–∑ CSV)
            if 'keywords' in df.columns and loaded_from == 'csv':
                 print("–û–±—Ä–∞–±–æ—Ç–∫–∞ 'keywords' (–∏–∑ CSV)...")
                 def safe_literal_eval(val):
                    if isinstance(val, list): return val
                    try:
                        if pd.isna(val) or not isinstance(val, str): return []
                        if not val.strip() or val.strip() == '[]': return []
                        if val.startswith("'") and val.endswith("'"): val = val[1:-1]
                        res = literal_eval(val)
                        return res if isinstance(res, list) else []
                    except: return []
                 df['keywords'] = df['keywords'].apply(safe_literal_eval)
            elif 'keywords' in df.columns:
                 # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞, –µ—Å–ª–∏ –∏–∑ pickle
                 df['keywords'] = df['keywords'].apply(lambda x: x if isinstance(x, list) else [])

            # 3. Entry ID
            if 'entry_id' not in df.columns:
                print("Warning: Creating 'entry_id' from index.")
                df['entry_id'] = df.index
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ç–∏–ø int –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            df['entry_id'] = df['entry_id'].astype(int)

            # 4. –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ NaN –≤ event-–∫–æ–ª–æ–Ω–∫–∞—Ö
            event_cols = ['event_id', 'event_name', 'description', 'date_in_text', 'location',
                          'historical_context', 'confidence', 'classification_confidence', 'text_fragment']
            for col in event_cols:
                if col in df.columns:
                    df[col] = df[col].fillna('N/A')
                else:
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ CSV)
                    df[col] = 'N/A'
                    print(f"Warning: Added missing column '{col}' with 'N/A'.")


            print("–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
            return df
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return pd.DataFrame()
    else:
        return pd.DataFrame()

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ö–∞—Ä—Ç—ã –ó–Ω–∞–Ω–∏–π ---
def get_categories():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (category_id, category_name) –¥–ª—è selectbox."""
    return [(cat['category_id'], cat['category_name']) for cat in KNOWLEDGE_MAP]

def get_subcategories(category_id):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."""
    if not category_id: return []
    for cat in KNOWLEDGE_MAP:
        if cat['category_id'] == category_id and 'subcategories' in cat:
            return [(sub['subcategory_id'], sub['subcategory_name']) for sub in cat['subcategories']]
    return []

def get_events(subcategory_id):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–±—ã—Ç–∏–π –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏."""
    if not subcategory_id: return []
    for cat in KNOWLEDGE_MAP:
        if 'subcategories' in cat:
            for subcat in cat['subcategories']:
                if subcat['subcategory_id'] == subcategory_id and 'events' in subcat:
                    return [(ev['event_id'], ev['event_name']) for ev in subcat['events']]
    return []

def get_full_event_name(event_id):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–µ –∏–º—è –¥–ª—è event_id (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)."""
    if not event_id or event_id == 'N/A' or event_id == 'OTHER':
        return event_id
    if event_id in KM_EVENT_NAMES: return KM_EVENT_NAMES[event_id]
    if event_id in KM_SUBCATEGORY_NAMES: return KM_SUBCATEGORY_NAMES[event_id]
    if event_id in KM_CATEGORY_NAMES: return KM_CATEGORY_NAMES[event_id]
    return event_id # –í–æ–∑–≤—Ä–∞—â–∞–µ–º ID, –µ—Å–ª–∏ –∏–º—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
df_merged = load_data(DATA_PATH_PKL, DATA_PATH_CSV)

# --- –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
st.title("–ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π –≤ –¥–Ω–µ–≤–Ω–∏–∫–µ –≥–∏–º–Ω–∞–∑–∏—Å—Ç–∞ XIX –≤–µ–∫–∞ (v3)")

if df_merged.empty:
    st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.")
    st.stop()

# --- –§–∏–ª—å—Ç—Ä—ã –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ ---
st.sidebar.header("–§–∏–ª—å—Ç—Ä—ã –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")

# –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
df_filtered = df_merged.copy()

# --- –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π —Ñ–∏–ª—å—Ç—Ä –ø–æ –ö–∞—Ä—Ç–µ –ó–Ω–∞–Ω–∏–π ---
st.sidebar.subheader("–§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Å–æ–±—ã—Ç–∏–π")
categories = get_categories()
# –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏—é "–í—Å–µ"
category_options = [("ALL", "–í—Å–µ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏")] + categories
selected_cat_tuple = st.sidebar.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é:",
    options=category_options,
    format_func=lambda x: x[1], # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–º—è, —Ö—Ä–∞–Ω–∏–º ID
    key='cat_filter'
)
selected_cat_id = selected_cat_tuple[0] if selected_cat_tuple else None

# –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ –Ω–µ "–í—Å–µ"
if selected_cat_id and selected_cat_id != "ALL":
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ event_id –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å ID –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–ª–∏ —Ä–∞–≤–µ–Ω –µ–º—É, –∏–ª–∏ —Ä–∞–≤–µ–Ω 'OTHER', –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ 'OTHER'
    # –¢–∞–∫–∂–µ —É—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Å–æ–±—ã—Ç–∏—è –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    df_filtered = df_filtered[
        df_filtered['event_id'].notna() & df_filtered['event_id'].apply(
            lambda x: x == selected_cat_id or (isinstance(x, str) and x.startswith(selected_cat_id + '_'))
        )
    ]
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–ø—Ü–∏–∏ –¥–ª—è –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π
    subcategories = get_subcategories(selected_cat_id)
    subcategory_options = [("ALL", "–í—Å–µ –ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏")] + subcategories
else:
    subcategory_options = [("ALL", "–í—Å–µ –ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏")] # –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –≤—ã–±—Ä–∞–Ω–∞, –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º

selected_subcat_tuple = st.sidebar.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—é:",
    options=subcategory_options,
    format_func=lambda x: x[1],
    key='subcat_filter',
    disabled=(selected_cat_id is None or selected_cat_id == "ALL") # –ë–ª–æ–∫–∏—Ä—É–µ–º, –µ—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –≤—ã–±—Ä–∞–Ω–∞
)
selected_subcat_id = selected_subcat_tuple[0] if selected_subcat_tuple else None

# –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
if selected_subcat_id and selected_subcat_id != "ALL":
     df_filtered = df_filtered[
        df_filtered['event_id'].notna() & df_filtered['event_id'].apply(
            lambda x: x == selected_subcat_id or (isinstance(x, str) and x.startswith(selected_subcat_id + '_'))
        )
    ]
     event_options = [("ALL", "–í—Å–µ –°–æ–±—ã—Ç–∏—è")] + get_events(selected_subcat_id)
else:
    event_options = [("ALL", "–í—Å–µ –°–æ–±—ã—Ç–∏—è")]

selected_event_tuple = st.sidebar.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ:",
    options=event_options,
    format_func=lambda x: x[1],
    key='event_filter',
    disabled=(selected_subcat_id is None or selected_subcat_id == "ALL") # –ë–ª–æ–∫–∏—Ä—É–µ–º, –µ—Å–ª–∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –≤—ã–±—Ä–∞–Ω–∞
)
selected_event_id = selected_event_tuple[0] if selected_event_tuple else None

# –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Å–æ–±—ã—Ç–∏—é
if selected_event_id and selected_event_id != "ALL":
    df_filtered = df_filtered[df_filtered['event_id'] == selected_event_id]

# --- –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã (–ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –∫ —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–æ –∏–µ—Ä–∞—Ä—Ö–∏–∏ –¥–∞–Ω–Ω—ã–º) ---
st.sidebar.subheader("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã")

# --- –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ ---
date_col_present = 'source_date_dt' in df_filtered.columns and not df_filtered['source_date_dt'].isna().all()
if date_col_present and not df_filtered.empty: # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–∏—Å—å –¥–∞–Ω–Ω—ã–µ
    min_date_val = df_filtered['source_date_dt'].min()
    max_date_val = df_filtered['source_date_dt'].max()
    if pd.notna(min_date_val) and pd.notna(max_date_val):
        min_date = min_date_val.date()
        max_date = max_date_val.date()
        if min_date <= max_date:
            try:
                date_range = st.sidebar.date_input(
                    "–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –∑–∞–ø–∏—Å–µ–π:",
                    value=(min_date, max_date),
                    min_value=min_date, max_value=max_date, key='date_filter'
                )
                if len(date_range) == 2:
                    start_date, end_date = date_range
                    df_filtered = df_filtered[
                        df_filtered['source_date_dt'].notna() &
                        (df_filtered['source_date_dt'].dt.date >= start_date) &
                        (df_filtered['source_date_dt'].dt.date <= end_date) ]
            except Exception as e: st.sidebar.error(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–µ: {e}")
        else: st.sidebar.warning("–ù–µ–∫–æ—Ä—Ä. –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
    else: st.sidebar.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç.")
# else: st.sidebar.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–µ.") # –ú–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≥—Ä–æ–º–æ–∂–¥–∞—Ç—å


# --- –§–∏–ª—å—Ç—Ä –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º ---
keywords_col_present = 'keywords' in df_filtered.columns
if keywords_col_present and not df_filtered.empty:
    all_keywords_flat = [k for sublist in df_filtered['keywords'].dropna() if isinstance(sublist, list) for k in sublist if k and isinstance(k, str)]
    unique_keywords = sorted(list(set(all_keywords_flat)))
    if unique_keywords:
        selected_keywords = st.sidebar.multiselect(
            "–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–ò):", options=unique_keywords, key='keyword_filter'
        )
        if selected_keywords:
            def check_keywords(kw_list): return isinstance(kw_list, list) and all(k in kw_list for k in selected_keywords)
            df_filtered = df_filtered[df_filtered['keywords'].apply(check_keywords)]
# else: st.sidebar.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º.")


# --- –§–∏–ª—å—Ç—Ä –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è) ---
confidence_col_present = 'confidence' in df_filtered.columns
if confidence_col_present and not df_filtered.empty:
    confidence_levels = sorted([lvl for lvl in df_filtered['confidence'].dropna().unique() if lvl != 'N/A'])
    if confidence_levels:
        selected_confidence = st.sidebar.multiselect(
            "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è):", options=confidence_levels, key='confidence_filter'
        )
        if selected_confidence:
            df_filtered = df_filtered[df_filtered['confidence'].isin(selected_confidence)]
# else: st.sidebar.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏.")

# --- –§–∏–ª—å—Ç—Ä –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è) ---
class_confidence_col_present = 'classification_confidence' in df_filtered.columns
if class_confidence_col_present and not df_filtered.empty:
    class_confidence_levels = sorted([lvl for lvl in df_filtered['classification_confidence'].dropna().unique() if lvl != 'N/A'])
    if class_confidence_levels:
        selected_class_confidence = st.sidebar.multiselect(
            "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è):", options=class_confidence_levels, key='class_confidence_filter'
        )
        if selected_class_confidence:
            df_filtered = df_filtered[df_filtered['classification_confidence'].isin(selected_class_confidence)]
# else: st.sidebar.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.")


# --- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---
st.header("–û–±–∑–æ—Ä –∑–∞–ø–∏—Å–µ–π –∏ —Å–æ–±—ã—Ç–∏–π (–æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ)")
display_columns = ['entry_id', 'date', 'event_id', 'event_name', 'description', 'location',
                   'confidence', 'classification_confidence', 'keywords']
actual_display_columns = [col for col in display_columns if col in df_filtered.columns]

if not df_filtered.empty:
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É—Ä–µ–∑–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –æ–±–∑–æ—Ä–∞
    st.dataframe(df_filtered[actual_display_columns], height=300) # –û–≥—Ä–∞–Ω–∏—á–∏–º –≤—ã—Å–æ—Ç—É
    st.write(f"–û—Ç–æ–±—Ä–∞–Ω–æ —Å—Ç—Ä–æ–∫: {len(df_filtered)}")
else:
    st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º.")


# --- –î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–ø–∏—Å–∏ ---
st.header("–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–ø–∏—Å–∏")

entry_id_present = 'entry_id' in df_filtered.columns
if not df_filtered.empty and entry_id_present:
    available_entry_ids = sorted(df_filtered['entry_id'].unique())
    if available_entry_ids:
        selected_entry_id = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ ID –∑–∞–ø–∏—Å–∏ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞:",
            options=available_entry_ids, key='entry_selector', index=None, placeholder="–í—ã–±–µ—Ä–∏—Ç–µ ID..."
        )
        if selected_entry_id is not None:
            entry_data_full = df_merged[df_merged['entry_id'] == selected_entry_id]
            if not entry_data_full.empty:
                diary_date = entry_data_full['date'].iloc[0] if 'date' in entry_data_full.columns else 'N/A'
                diary_text = entry_data_full['text'].iloc[0] if 'text' in entry_data_full.columns else '–¢–µ–∫—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'

                st.subheader(f"–ó–∞–ø–∏—Å—å –æ—Ç {diary_date} (ID: {selected_entry_id})")
                st.markdown("#### –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–ø–∏—Å–∏:")
                st.markdown(f"<div style='height: 300px; overflow-y: auto; border: 1px solid #ccc; padding: 10px; background-color: #f9f9f9;'>{diary_text}</div>", unsafe_allow_html=True)

                st.subheader("–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è:")
                events_in_entry = entry_data_full[
                    entry_data_full['event_name'].notna() & (entry_data_full['event_name'] != 'N/A')
                ].drop_duplicates(subset=['event_name', 'text_fragment'])

                if not events_in_entry.empty:
                    for i, (_, event_row) in enumerate(events_in_entry.iterrows()):
                        st.markdown("---")
                        event_name_display = event_row.get('event_name', 'N/A')
                        event_id_display = event_row.get('event_id', 'N/A')
                        full_hierarchical_name = get_full_event_name(event_id_display) # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –∏–∑ –∫–∞—Ä—Ç—ã

                        st.markdown(f"**–°–æ–±—ã—Ç–∏–µ {i+1}: {event_name_display}**")
                        with st.expander(f"–ü–æ–¥—Ä–æ–±–Ω–µ–µ: {event_name_display} (ID: {event_id_display})"):
                            if full_hierarchical_name != event_id_display: # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—é –µ—Å–ª–∏ –Ω–∞—à–ª–∏
                                 st.markdown(f"**–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:** {full_hierarchical_name} (`{event_id_display}`)")
                            else:
                                 st.markdown(f"**–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ID:** `{event_id_display}`")

                            st.markdown(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è):** {event_row.get('classification_confidence', 'N/A')}")
                            st.markdown(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è):** {event_row.get('confidence', 'N/A')}")
                            st.markdown(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {event_row.get('description', 'N/A')}")
                            st.markdown(f"**–î–∞—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ:** {event_row.get('date_in_text', 'N/A')}")
                            st.markdown(f"**–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ:** {event_row.get('location', 'N/A')}")

                            keywords = event_row.get('keywords', [])
                            if isinstance(keywords, list) and keywords:
                                valid_keywords = [str(k).strip() for k in keywords if k and isinstance(k, str) and str(k).strip()]
                                if valid_keywords: st.markdown(f"**–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:** {' | '.join([f'`{k}`' for k in valid_keywords])}")
                            elif keywords != 'N/A': st.markdown(f"**–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:** {keywords}")

                            st.markdown(f"**–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:**")
                            st.caption(f"{event_row.get('historical_context', 'N/A')}")

                            st.markdown(f"**–¶–∏—Ç–∏—Ä—É–µ–º—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞:**")
                            st.info(f"{event_row.get('text_fragment', 'N/A')}")
                else:
                    st.info("–î–ª—è —ç—Ç–æ–π –∑–∞–ø–∏—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π.")
            else:
                 st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ —Å ID {selected_entry_id}.")
    else:
        st.info("–ù–µ—Ç –∑–∞–ø–∏—Å–µ–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ç–µ–∫—É—â–∏–º —Ñ–∏–ª—å—Ç—Ä–∞–º, –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞.")
else:
    st.info("–ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–µ—Ç–∞–ª–µ–π –∑–∞–ø–∏—Å–µ–π.")
    if not entry_id_present: st.warning("–ö–æ–ª–æ–Ω–∫–∞ 'entry_id' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö.")


# --- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ —Å–æ–±—ã—Ç–∏–π ---
st.header("–í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ —Å–æ–±—ã—Ç–∏–π")

timeline_possible = ('source_date_dt' in df_filtered.columns and
                     'event_name' in df_filtered.columns and
                     not df_filtered.empty)

if timeline_possible:
    timeline_data = df_filtered[
        (df_filtered['event_name'] != 'N/A') & df_filtered['source_date_dt'].notna()
    ].copy()

    if not timeline_data.empty:
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–æ–±—ã—Ç–∏—è
        group_by_category = st.checkbox("–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª–µ", key="group_timeline")

        timeline_data.set_index('source_date_dt', inplace=True)
        aggregation_period = st.selectbox(
            "–ü–µ—Ä–∏–æ–¥ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏:",
            options=['D', 'W', 'M', 'Q', 'Y'], index=2,
            format_func=lambda x: {'D':'–î–µ–Ω—å', 'W':'–ù–µ–¥–µ–ª—è', 'M':'–ú–µ—Å—è—Ü', 'Q':'–ö–≤–∞—Ä—Ç–∞–ª', 'Y':'–ì–æ–¥'}.get(x, x),
            key='timeline_agg'
        )

        try:
            if group_by_category and 'event_id' in timeline_data.columns:
                 # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è –∏–∑ event_id
                 timeline_data['category_id'] = timeline_data['event_id'].apply(
                     lambda x: x.split('_')[0] if isinstance(x, str) and '_' in x else 'OTHER'
                 )
                 # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–µ—Ä–∏–æ–¥—É –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –∑–∞—Ç–µ–º —Å—á–∏—Ç–∞–µ–º
                 timeline_counts = timeline_data.groupby([
                     pd.Grouper(freq=aggregation_period),
                     'category_id'
                 ]).size().unstack(fill_value=0) # unstack –¥–µ–ª–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
                 # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –ª–µ–≥–µ–Ω–¥—ã
                 timeline_counts.rename(columns=KM_CATEGORY_NAMES, inplace=True)

            else:
                 timeline_counts = timeline_data.resample(aggregation_period).size()
                 timeline_counts = timeline_counts.rename("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π")

            if not timeline_counts.empty:
                st.line_chart(timeline_counts)
                grouping_text = " —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º" if group_by_category and 'category_id' in timeline_data.columns else ""
                st.caption(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º '{aggregation_period}'{grouping_text} (–Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞—Ç—ã –∑–∞–ø–∏—Å–∏).")
            else:
                st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã: {e}")
            st.exception(e) # –ü–æ–∫–∞–∑–∞—Ç—å traceback –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

    else:
        st.info("–ù–µ—Ç —Å–æ–±—ã—Ç–∏–π —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏ –≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã.")
else:
    st.info("–ù–µ–æ–±—Ö–æ–¥–∏–º—ã –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏ ('source_date') –∏ —Å–æ–±—ã—Ç–∏—è–º–∏ ('event_name') –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã.")

# --- –ö–æ–Ω–µ—Ü –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---