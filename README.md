# Анализ исторических дневников: Извлечение событий революций 1848-1849 гг. с помощью LLM

## Описание проекта

Данный проект представляет собой Python-скрипт, предназначенный для автоматического анализа текстов личных дневников XIX века. Основная цель — выявление, извлечение и структурирование упоминаний, связанных с европейскими революциями 1848-1849 годов («Весна народов») и реакцией на эти события в Российской Империи. Для выполнения этой задачи используются большие языковые модели (LLM) через API Google Generative AI (Gemini).

Проект ориентирован на исследователей-историков, предоставляя инструмент для первичной обработки больших объемов текстовых данных и выделения релевантной информации для последующего глубокого анализа.

## Ключевые возможности

*   **Двухэтапная обработка LLM:**
    1.  **Извлечение (Extraction):** Первая модель анализирует текст дневниковой записи и извлекает потенциально релевантные фрагменты, связанные с революциями 1848-1849 гг.
    2.  **Верификация (Verification):** Вторая модель критически оценивает и при необходимости корректирует информацию, извлеченную на первом этапе, повышая точность и надежность результатов.
*   **Использование Карты Знаний:**
    *   Скрипт использует предопределенную, иерархическую Карту Знаний (Knowledge Map), которая описывает ключевые события, регионы, аспекты реакции и типы восприятия, связанные с революциями 1848-1849 гг.
    *   Это позволяет стандартизировать классификацию извлеченных событий и присваивать им уникальные идентификаторы (`event_id`).
    *   Карта Знаний встроена в скрипт в формате Markdown для удобства редактирования (или может быть вынесена во внешний JSON-файл в альтернативных версиях скрипта).
*   **Структурированный вывод данных:**
    *   Извлеченная информация о каждом событии сохраняется в виде структурированного JSON-объекта.
    *   Для определения и валидации структуры этих объектов используется библиотека Pydantic.
*   **Отказоустойчивость и возобновляемость:**
    *   Скрипт сохраняет прогресс обработки, записывая ID последней успешно обработанной записи.
    *   Промежуточные результаты для каждой записи и общий накопленный результат сохраняются во временные файлы.
    *   Это позволяет возобновить работу скрипта с места остановки в случае сбоя или прерывания, экономя время и API-вызовы.
*   **Управление API-запросами:**
    *   Встроен механизм для контроля частоты обращений к API Google Gemini, чтобы не превышать установленные лимиты.
    *   Реализованы повторные попытки выполнения запросов в случае временных ошибок API.
*   **Детальное логирование:**
    *   Весь процесс работы скрипта, включая информационные сообщения, предупреждения и ошибки, логируется как в консоль, так и в файл (`processing.log`).
*   **Гибкие настройки безопасности API:** Параметры безопасности для API Gemini настроены таким образом, чтобы минимизировать блокировку ответов из-за специфики исторического контента, который может содержать устаревшие или спорные формулировки.

## Технологический стек

*   **Python 3.8+**
*   **Библиотеки:**
    *   `pandas`: для чтения и обработки входных CSV-данных.
    *   `google-generativeai`: для взаимодействия с API Google Gemini.
    *   `pydantic`: для валидации и моделирования данных.
    *   `python-dotenv`: для управления переменными окружения (например, API-ключом).
    *   `logging`: для ведения журнала событий.

## Установка и запуск

### Предварительные требования

*   Установленный Python 3.8 или выше.
*   Аккаунт Google Cloud с доступом к Vertex AI или аккаунт Google AI Studio и сгенерированный API-ключ для моделей Gemini.
*   Исходные данные: CSV-файл (`diary_with_id.csv` по умолчанию), содержащий как минимум следующие колонки:
    *   `entry_id`: Уникальный числовой идентификатор записи.
    *   `date`: Дата дневниковой записи (например, "YYYY-MM-DD").
    *   `text`: Текст дневниковой записи.

### Шаги по установке

1.  **Клонируйте репозиторий:**
    ```bash
    git clone [URL_вашего_репозитория]
    cd [название_папки_репозитория]
    ```

2.  **Создайте и активируйте виртуальное окружение (рекомендуется):**
    ```bash
    python -m venv venv
    # Для Windows:
    venv\Scripts\activate
    # Для macOS/Linux:
    source venv/bin/activate
    ```

3.  **Установите зависимости:**
    ```bash
    pip install -r requirements.txt
    ```
    (Файл `requirements.txt` должен быть создан на основе используемых версий библиотек).

4.  **Настройте переменные окружения:**
    *   Создайте файл `.env` в корневой директории проекта.
    *   Добавьте в него ваш API-ключ:
        ```
        GEMINI_API_KEY="ВАШ_API_КЛЮЧ_GEMINI"
        ```
    *   Вы можете использовать файл `.env.example` как шаблон.

5.  **Подготовьте данные:**
    *   Поместите ваш CSV-файл с дневниковыми записями в корневую директорию проекта или укажите корректный путь в переменной `DATA_PATH` в скрипте.
    *   Если вы используете вариант скрипта с Картой Знаний во внешнем файле, убедитесь, что `knowledge_map.json` находится по указанному пути (по умолчанию, в корне проекта).

### Запуск скрипта

Выполните скрипт из корневой директории проекта:
```bash
python src/info_extraction.py


## Процесс работы скрипта

1.  **Инициализация:** Загрузка конфигурации, переменных окружения, настройка логирования.
2.  **Загрузка Карты Знаний:** Если Карта Знаний хранится во внешнем файле, она загружается и форматируется для передачи в LLM. Если встроена – используется напрямую.
3.  **Инициализация моделей LLM:** Создаются экземпляры моделей Gemini для извлечения и верификации.
4.  **Проверка состояния:** Скрипт проверяет наличие файлов `last_processed.txt` и `revolution_events_temp.json` для возобновления работы.
5.  **Чтение данных:** Дневниковые записи загружаются из CSV-файла.
6.  **Итеративная обработка записей:**
    *   Для каждой записи, которая еще не была обработана:
        *   Проверяется наличие индивидуального временного файла (например, `temp/entry_ID.json`). Если он существует, результаты загружаются из него.
        *   В противном случае:
            *   **Извлечение:** Текст записи передается модели-экстрактору вместе с Картой Знаний. Модель возвращает список JSON-объектов с потенциальными событиями.
            *   **Верификация:** Каждый извлеченный объект передается модели-верификатору вместе с полным текстом записи и Картой Знаний. Модель проверяет и корректирует данные.
            *   **Валидация:** Скорректированные данные валидируются с помощью Pydantic-модели `RevolutionEvent`.
            *   Результаты для текущей записи сохраняются в ее индивидуальный временный файл.
        *   Все обработанные события добавляются в общий список.
        *   Общий список событий и ID последней обработанной записи сохраняются.
7.  **Сохранение финальных результатов:** По завершении обработки всех записей, итоговый список событий сохраняется в файл `revolution_events.json`.

## Структура выходных данных

Каждое извлеченное и верифицированное событие представлено JSON-объектом следующей структуры (определенной Pydantic-моделью `RevolutionEvent`):

```json
{
    "entry_id": 123, // Идентификатор записи дневника
    "event_id": "REV1848_FRA_FEB", // ID события из Карты Знаний
    "event_name": "Февральская революция / Свержение монархии", // Название события
    "event_subtype_custom": null, // Детальное уточнение, если event_name общий
    "description": "В газетах пишут о свержении короля во Франции и провозглашении республики.", // Описание события из текста
    "date_in_text": "февраль 1848", // Дата события, упомянутая в тексте (если есть)
    "source_date": "1848-03-15", // Дата дневниковой записи
    "location": "Париж, Франция", // Место события из текста
    "location_normalized": "Франция", // Нормализованное место
    "brief_context": "Февральская революция 1848 года во Франции привела к отречению короля Луи-Филиппа I и установлению Второй республики.", // Краткий исторический контекст
    "information_source": "Газеты", // Источник информации для автора дневника
    "information_source_type": "Официальные источники (газеты, манифесты)", // Категория источника
    "confidence": "High", // Уверенность в корректности извлеченных данных
    "classification_confidence": "High", // Уверенность в правильности event_id
    "keywords": ["Франция", "революция", "король", "республика"], // Ключевые слова
    "text_fragment": "Сегодня читал в газетах о новых беспорядках во Франции. Говорят, король бежал, и провозглашена республика. Что-то будет!" // Точный фрагмент текста
}
```

## Файловая структура (рекомендуемая)

```
.
├── .env                   # Переменные окружения (API-ключ)
├── .env.example           # Шаблон для .env
├── .gitignore             # Файлы, игнорируемые Git
├── README.md              # Этот файл
├── requirements.txt       # Зависимости Python
├── src/
│   └── info_extraction.py # Основной скрипт Python
├── knowledge_map.json     # (Опционально) Карта Знаний в JSON-формате
├── data/
│   └── diary_with_id.csv  # Входной CSV-файл с дневниками
├── temp/                  # Временные файлы для каждой записи (создается скриптом)
├── processing.log         # Лог-файл работы скрипта (создается скриптом)
├── last_processed.txt     # ID последней обработанной записи (создается скриптом)
├── revolution_events_temp.json # Промежуточные результаты (создается скриптом)
└── revolution_events.json # Финальные результаты (создается скриптом)
```
## Лицензия

(Укажите здесь тип лицензии, если проект распространяется под определенной лицензией, например, MIT, Apache 2.0 и т.д.)
