# Анализ исторических дневников: Извлечение событий революций 1848-1849 гг. с помощью LLM

## Описание проекта

Данный проект представляет собой Python-скрипт, предназначенный для автоматического анализа текстов личных дневников XIX века. Основная цель — выявление, извлечение и структурирование упоминаний, связанных с европейскими революциями 1848-1849 годов («Весна народов») и реакцией на эти события в Российской Империи. Для выполнения этой задачи используются большие языковые модели (LLM), доступные через OpenAI-совместимые API, с конфигурацией по умолчанию для **Google Gemini**.

Проект ориентирован на исследователей-историков, предоставляя инструмент для первичной обработки больших объемов текстовых данных и выделения релевантной информации для последующего глубокого анализа.

## Ключевые возможности

*   **Продвинутое извлечение данных с помощью LLM:**
    *   Скрипт использует мощную модель (например, `gemini-1.5-pro`) в рамках единого, тщательно спроектированного промпта.
    *   Модель одновременно выполняет задачи **извлечения релевантных фрагментов**, их **анализа** и **классификации** согласно предоставленной Карте Знаний, что обеспечивает высокую точность и консистентность результатов.
*   **Использование Карты Знаний:**
    *   Скрипт использует предопределенную, иерархическую Карту Знаний (`knowledge_map.json`), которая описывает ключевые события, регионы, аспекты реакции и типы восприятия, связанные с революциями 1848-1849 гг.
    *   Это позволяет стандартизировать классификацию извлеченных событий и присваивать им уникальные идентификаторы (`event_id`).
*   **Структурированный и валидированный вывод данных:**
    *   Извлеченная информация о каждом событии сохраняется в виде структурированного JSON-объекта.
    *   Для строгой валидации структуры и типов данных этих объектов используется библиотека **Pydantic**, что гарантирует чистоту и предсказуемость итогового набора данных.
*   **Надежная отказоустойчивость и возобновляемость:**
    *   Скрипт сохраняет ID последней успешно обработанной записи в файл `last_processed.txt`.
    *   Результаты для каждой отдельной записи кэшируются в индивидуальные файлы в директории `temp/`.
    *   Общий накопленный результат постоянно сохраняется в промежуточный файл `results/revolution_events_temp.json`.
    *   Эта многоуровневая система позволяет возобновить работу скрипта с точного места остановки в случае сбоя, экономя время и API-вызовы.
*   **Управление API-запросами:**
    *   Встроен механизм для контроля частоты обращений к API, чтобы не превышать установленные лимиты (по умолчанию 15 запросов в минуту).
    *   Реализованы автоматические повторные попытки (до 3 раз) с экспоненциальной задержкой в случае временных ошибок API.
*   **Детальное логирование:**
    *   Весь процесс работы скрипта, включая информационные сообщения, предупреждения и ошибки, подробно логируется как в консоль, так и в файл `processing.log`.
*   **Продвинутый промпт-инжиниринг:**
    *   Системный промпт содержит детальные инструкции, few-shot примеры и явное указание на научный контекст исследования. Это минимизирует вероятность блокировки ответов из-за специфики исторического контента, который может содержать устаревшие или спорные формулировки.

## Технологический стек

*   **Python 3.8+**
*   **Библиотеки:**
    *   `pandas`: для чтения и обработки входных CSV-данных.
    *   `openai`: используется как универсальный клиент для взаимодействия с OpenAI-совместимыми API (включая Google Gemini).
    *   `pydantic`: для валидации и моделирования данных.
    *   `python-dotenv`: для управления переменными окружения (например, API-ключом).
    *   `logging`: для ведения журнала событий.

## Установка и запуск

### Предварительные требования

*   Установленный Python 3.8 или выше.
*   API-ключ для доступа к модели LLM (например, из Google AI Studio для Gemini).
*   Исходные данные: CSV-файл (по умолчанию `data/diary_with_id.csv`), содержащий как минимум следующие колонки:
    *   `entry_id`: Уникальный числовой идентификатор записи.
    *   `date`: Дата дневниковой записи (например, "YYYY-MM-DD").
    *   `text`: Текст дневниковой записи.

### Шаги по установке

1.  **Клонируйте репозиторий:**
    ```bash
    git clone [URL_вашего_репозитория]
    cd [название_папки_репозитория]
    ```

2.  **Создайте и активируйте виртуальное окружение (рекомендуется):**
    ```bash
    python -m venv venv
    # Для Windows:
    venv\Scripts\activate
    # Для macOS/Linux:
    source venv/bin/activate
    ```

3.  **Установите зависимости:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Настройте переменные окружения:**
    *   Создайте файл `.env` в корневой директории проекта.
    *   Добавьте в него ваш API-ключ:
        ```
        GEMINI_API_KEY="ВАШ_API_КЛЮЧ_GEMINI"
        ```

5.  **Подготовьте данные:**
    *   Поместите ваш CSV-файл с дневниковыми записями в папку `data/`.
    *   Убедитесь, что файл `knowledge_map.json` находится в корне проекта.

### Запуск скрипта

Выполните скрипт из корневой директории проекта:
```bash
python src/info_extraction.py
```

## Процесс работы скрипта

1.  **Инициализация:** Загрузка конфигурации, API-ключа, настройка логирования.
2.  **Загрузка Карты Знаний:** Карта Знаний из `knowledge_map.json` загружается и форматируется для передачи в LLM.
3.  **Проверка состояния:** Скрипт проверяет наличие файлов `last_processed.txt` и `results/revolution_events_temp.json` для определения точки возобновления работы.
4.  **Чтение данных:** Дневниковые записи загружаются из CSV-файла.
5.  **Итеративная обработка записей:**
    *   Для каждой записи, которая еще не была обработана:
        *   Скрипт проверяет наличие индивидуального файла в `temp/entry_{ID}.json`. Если он существует, результаты загружаются из него, пропуская API-вызов.
        *   Если кэша нет, текст записи, дата и Карта Знаний передаются в модель LLM.
        *   Модель возвращает JSON-массив с извлеченными и классифицированными событиями.
        *   Каждый объект в ответе валидируется с помощью Pydantic-модели `RevolutionEvent`.
        *   Результаты для текущей записи сохраняются в ее индивидуальный файл в `temp/`.
    *   Все валидированные события добавляются в общий список.
    *   Общий список и ID последней обработанной записи сохраняются в `results/revolution_events_temp.json` и `last_processed.txt` соответственно.
6.  **Сохранение финальных результатов:** По завершении обработки всех записей, итоговый список событий сохраняется в файл `results/revolution_events.json`.

## Структура выходных данных

Каждое извлеченное и верифицированное событие представлено JSON-объектом следующей структуры (определенной Pydantic-моделью `RevolutionEvent`):

```json
{
    "entry_id": 97,
    "event_id": "AUTHOR_PERCEPTION_OPINION_AUTH",
    "event_name": "Выражение поддержки/осуждения действий властей/конкретных государств",
    "event_subtype_custom": "Уверенность в стабильности режима Николая I",
    "description": "Автор выражает личное убеждение и поддержку действующей власти, заявляя, что пока правит «мудрый венценосец» Николай I, революционный переворот в России невозможен.",
    "date_in_text": null,
    "source_date": "1849-04-08",
    "location": "Россия",
    "location_normalized": "Россия",
    "brief_context": "Правление Николая I характеризовалось жестким подавлением любого инакомыслия и насаждением консервативной идеологии, что формировало у части общества уверенность в незыблемости самодержавия.",
    "information_source": "Личное мнение автора",
    "information_source_type": "Личные наблюдения и опыт автора",
    "confidence": "High",
    "classification_confidence": "High",
    "keywords": [ "Николай I", "поддержка власти", "мудрый венценосец", "переворот", "личное мнение" ],
    "text_fragment": "...но пока царствует такой мудрый венценосец, как Николай Первый, этого никогда не может случиться..."
}
```

## Файловая структура проекта

```
.
├── .env                         # Переменные окружения (API-ключ)
├── .gitignore                   # Файлы, игнорируемые Git
├── README.md                    # Этот файл
├── requirements.txt             # Зависимости Python
├── src/
│   └── info_extraction.py       # Основной скрипт Python
├── knowledge_map.json           # Карта Знаний в JSON-формате
├── data/
│   └── diary_with_id.csv        # Входной CSV-файл с дневниками
├── results/                     # Директория для итоговых файлов
│   ├── revolution_events.json   # Финальные результаты (создается скриптом)
│   └── revolution_events_temp.json # Промежуточные результаты (создается скриптом)
├── temp/                        # Кэш для отдельных записей (создается скриптом)
│   └── entry_7.json
│   └── ...
├── last_processed.txt           # ID последней обработанной записи (создается скриптом)
└── processing.log               # Лог-файл работы скрипта (создается скриптом)
```

## Лицензия

MIT License

Copyright (c) 2025 Кузнецов Алексей